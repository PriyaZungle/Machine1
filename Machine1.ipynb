{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BY9u5iDFTqPJ"
      },
      "outputs": [],
      "source": [
        "# Assignment of Machine learning"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. What is a parameter?\n",
        "- A parameter is used to describe the entire population being studied.\n",
        "- For example, we want to know the average length of a caterpillars . - This is a parameter because it is states something about the entire population of caterpillars.\n",
        "\n",
        "2. What is correlation? What does negative correlation mean?\n",
        "- Correlation is a statistical measure that describes the strength and direction of the relationship between two variables.\n",
        "- A negative correlation exists when one variable increases as the other variable decreases, and vice versa.\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "- Machine Learing  is a field of AI that focuses on developing algorithms and models that allow computers to learn from data and make predictions or decisions without being explicitly programmed.\n",
        "- The main components of machine learning include data, algorithms, models, and predictions.\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "- A lower loss value generally indicates a better-performing model, as it signifies that the model's predictions are closer to the actual values.\n",
        "- The loss function quantifies the difference between predicted and actual outputs, guiding the model's training to minimize errors.\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "- Continuous variables represent data that can take any value within a range (like height, weight, or temperature).\n",
        "- Categorical variables represent data that falls into distinct, non-numeric categories or groups (like gender, color, or product type).\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "- To handle categorical variables in machine learning, we need to convert them into a numerical format that algorithms can understand.\n",
        "- Common techniques include\n",
        "    - one-hot encoding\n",
        "    -  label encoding\n",
        "    -  ordinal encoding\n",
        "    - target encoding\n",
        " each with its own strengths and weaknesses.\n",
        "\n",
        "7. What do you mean by training and testing a dataset?\n",
        "-  Training a dataset means using a portion of the data to teach a model to recognize patterns and make predictions.\n",
        "- Testing a dataset means evaluating the model's performance on a separate, unseen portion of the data to assess its accuracy and generalization ability.\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        "- Sklearn.preprocessing set of techniques and tools used to transform raw data into a format suitable for machine learning algorithms, improving their performance and accuracy.\n",
        "\n",
        "9. What is a Test set?\n",
        "-  A Test set is a separate portion of the data, withheld during model training, used to evaluate the final performance of a trained model on unseen data, providing an unbiased assessment of its generalization capabilities.\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
        "- To split data for model fitting in Python, use the train_test_split function from scikit-learn.\n",
        "- A common approach to a Machine Learning problem involves data collection, preparation, model selection, training, evaluation, and potentially hyperparameter tuning.\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "-  It helps you to  understand your data, identify potential problems, and make informed decisions about data cleaning, feature engineering, and model selection, ultimately leading to better model performance and insights.\n",
        "\n",
        "12. What is correlation?\n",
        "- Correlation refers to the statistical measure of the relationship between two variables, indicating how much they change together, either positively or negatively, and is used for data exploration, feature selection, and model evaluation.\n",
        "\n",
        "13. What does negative correlation mean?\n",
        "- A negative correlation means that as one variable increases, the other variable tends to decrease, or vice versa, indicating an inverse relationship.\n",
        "\n",
        "14. How can you find correlation between variables in Python?\n",
        "- The correlation between variables in python is  by calculating a matrix of the relationships between each pair of variables in the dataset.\n",
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "- Causation means that one event (the cause) directly leads to another event (the effect).\n",
        "- Correlation\n",
        "   - Two events occur together, but one doesn't necessarily cause the other\n",
        "   - Example: Ice cream sales and shark attacks increase during summer (correlation)\n",
        "- Causation\n",
        "  - One event directly causes another.\n",
        "  - Example :If you study, you get a good grade (studying causes good grade).\n",
        "\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "\n",
        "- An Optimizer is an algorithm that adjusts model parameters (like weights and biases) to minimize the loss function, thereby improving model performance.\n",
        "- Different types of optimizers include\n",
        "  - Gradient Descent (GD)\n",
        "     - A fundamental optimization algorithm that iteratively updates model parameters in the direction of the steepest descent of the loss function.\n",
        "     - Example: Imagine a ball rolling down a hill. GD updates the ball's position (model parameters) by moving it in the direction of the steepest slope (gradient) to reach the bottom (minimum loss).\n",
        "  - Stochastic Gradient Descent (SGD)\n",
        "     - An improvement over GD that uses a small batch of data to calculate the gradient, making it faster and more efficient, especially for large datasets.\n",
        "     - Example:  Instead of using the entire dataset to calculate the gradient, SGD uses a random subset (batch) of the data, allowing for faster updates and potentially escaping local minima more easily.\n",
        "  - Adam\n",
        "     - A popular optimizer that combines the advantages of both SGD and RMSprop, using adaptive learning rates and momentum to achieve faster and more stable convergence.\n",
        "     - Example:Adam adapts the learning rate for each parameter based on the history of gradients, allowing it to converge quickly to the optimal solution.\n",
        "\n",
        "17. What is sklearn.linear_model ?\n",
        "\n",
        "- The sklearn.linear_model is a module in Scikit-Learn that provides various linear models for regression and classification tasks.\n",
        "-  It includes models like Linear Regression, Logistic Regression, Ridge Regression, Lasso, ElasticNet, etc.\n",
        "- These models are useful for making predictions where the relationship between the independent and dependent variables is approximately linear.\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "\n",
        "- The .fit() method in Scikit-Learn is used to train a machine learning model on a given dataset.\n",
        "- It adjusts the model's internal parameters  based on the input data and corresponding labels.\n",
        "- Arguments for model.fit()\n",
        "    - 2D array-like (numpy array, pandas DataFrame, or list of lists).\n",
        "    - Shape: (n_samples, n_features), where:\n",
        "\n",
        "       - n_samples: Number of rows (data points).\n",
        "\n",
        "       - n_features: Number of features (columns).\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "- The model.predict() method in Scikit-Learn is used to generate predictions from a trained machine learning model.\n",
        "- Given a set of new input data (X), it returns predicted outputs (y_pred) based on the learned patterns during training.\n",
        "- Arguments for model.predict()\n",
        "    - Must be 2D array-like (numpy array, pandas DataFrame, or list of lists).\n",
        "  - Shape: (n_samples, n_features), where:\n",
        "\n",
        "     - n_samples: Number of new data points.\n",
        "\n",
        "     - n_features: Number of features (same as training data).\n",
        "20. What are continuous and categorical variables?\n",
        "- Continuous variables represent data that can take on any value within a given range (like temperature or height).\n",
        "- Categorical variables represent data that belongs to distinct categories or groups (like gender or color).\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "- Feature scaling is a preprocessing technique that normalizes the range of independent variables (features) in a dataset, ensuring they contribute equally to machine learning models, especially those sensitive to scale like gradient descent and distance-based algorithms.\n",
        "\n",
        "22. How do we perform scaling in Python?\n",
        "-  scaling is a crucial preprocessing step in machine learning that transforms numerical features to a standard range, improving model performance.\n",
        "\n",
        "- In Python, scaling is typically performed using Scikit-Learn sklearn.preprocessing module.\n",
        "\n",
        "23. What is sklearn.preprocessing?\n",
        "- The sklearn preprocessing refers to a set of techniques and tools used to transform raw data into a format suitable for machine learning algorithms, improving their performance and accuracy.\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "- To split data for model fitting, training, and testing in Python, use the train_test_split function from the scikit-learn library, specifying the dataset, and the desired test size.\n",
        "\n",
        "25. Explain data encoding?\n",
        "- Data encoding is the process of converting information into a specific format, often for storage, transmission, or analysis, making it machine-readable.\n",
        "-It involves transforming data from one form to another, like converting text or categorical data into numerical representations.\n"
      ],
      "metadata": {
        "id": "lEF33vjfT7JV"
      }
    }
  ]
}